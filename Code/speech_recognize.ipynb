{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(t):\n",
    "    start_time, end_time = map(int, t.split(\"_\"))\n",
    "    dur = end_time - start_time\n",
    "    return start_time, dur\n",
    "    \n",
    "def format_audio(audio_path, audio_file, output_path, format = 'flac'):\n",
    "    try:\n",
    "        audio_name = audio_file.split(\".\")[0]\n",
    "        audio = os.path.join(audio_path, audio_file)\n",
    "        export_path = os.path.join(output_path, audio_name) + f\".{format}\"\n",
    "        cmd = f'ffmpeg -i \\\"{audio}\\\"  -vn -ac 1 -ar {16000} -y \\\"{export_path}\\\"'\n",
    "        subprocess.call(cmd)\n",
    "    except Exception as ex:\n",
    "        print(\"Error: \", ex)\n",
    "    return f\"{export_path}\"\n",
    "\n",
    "def speech2text(path):\n",
    "    # load audio\n",
    "    audio_input, sample_rate = sf.read(path)\n",
    "    # pad input values and return pt tensor\n",
    "    input_values = processor(audio_input, sampling_rate=sample_rate, return_tensors=\"pt\").input_values.to(DEVICE)\n",
    "    # retrieve logits & take argmax\n",
    "    pred = model(input_values)\n",
    "    logits = pred.logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)[0]\n",
    "\n",
    "    # transcribe\n",
    "    transcription = processor.decode(predicted_ids)\n",
    "\n",
    "    return transcription\n",
    "\n",
    "def split_audio(audiopath, audio_name, output_path):\n",
    "    audiotype = audio_name.split(\".\")[-1]\n",
    "    # Read in audio\n",
    "    print('Loading audio..')\n",
    "    sound = AudioSegment.from_file(os.path.join(audiopath, audio_name), format=audiotype)\n",
    "    print(\"Loading done\")\n",
    "    # split\n",
    "    print('Start split')\n",
    "    chunks = split_on_silence(sound,min_silence_len=2000,silence_thresh=-70)#min_silence_len: split if silence is 0.3s。silence_thresh：less than -70dBFS is silence。\n",
    "    # Create saving folder\n",
    "    if not os.path.exists(output_path):os.mkdir(output_path)\n",
    "    print(\"Split done\")\n",
    "    # save splits\n",
    "    print('Saving...')\n",
    "    for i in range(len(chunks)):\n",
    "        new = chunks[i]\n",
    "        save_name = os.path.join(output_path, '%04d.%s'%(i,audiotype))\n",
    "        new.export(save_name, format = 'mp3')\n",
    "        print('%04d'%i,len(new))\n",
    "    print('Save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "BASE_PATH = os.path.abspath(os.path.join(os.path.abspath(\".\"), \"..\"))\n",
    "AUDIO_FOLDER = os.path.join(BASE_PATH, \"Audio\", \"Original\")\n",
    "SPLIT_AUDIO_FOLDER = os.path.join(BASE_PATH, \"Audio\", \"Splitted\")\n",
    "CLEAN_SPEECH_PATH = os.path.join(BASE_PATH, \"Audio\", \"Cleaned\")\n",
    "TRANSCIPTION_PATH = os.path.join(BASE_PATH, \"Transcription\")\n",
    "AUDIO = \"audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio..\n",
      "Loading done\n",
      "Start split\n",
      "Split done\n",
      "Saving...\n",
      "0000 6708\n",
      "0001 6468\n",
      "0002 12093\n",
      "0003 7941\n",
      "0004 6444\n",
      "0005 8032\n",
      "0006 149\n",
      "Save done\n"
     ]
    }
   ],
   "source": [
    "split_audio(AUDIO_FOLDER, AUDIO, SPLIT_AUDIO_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_NAMES = []\n",
    "for root, dir, files in os.walk(SPLIT_AUDIO_FOLDER):\n",
    "    AUDIO_NAMES += files\n",
    "CLEAN_SPEECH = [format_audio(SPLIT_AUDIO_FOLDER, audio_name, CLEAN_SPEECH_PATH, \"flac\") for audio_name in AUDIO_NAMES]\n",
    "AUDIO_PATH = [os.path.join(CLEAN_SPEECH_PATH, audio_name) for audio_name in CLEAN_SPEECH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles = pd.DataFrame(columns=[\"Name\", \"Path\", \"Text\"])\n",
    "subtitles['Name'] = AUDIO_NAMES\n",
    "subtitles[\"Path\"] = AUDIO_PATH\n",
    "subtitles[\"Text\"] = subtitles[\"Path\"].apply(lambda x: speech2text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Path</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.wav</td>\n",
       "      <td>e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...</td>\n",
       "      <td>HOW MANY HEARS OF THE DEPARTMENT ARE OLDER THA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.wav</td>\n",
       "      <td>e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...</td>\n",
       "      <td>LACE THE NAME BOARESTATE AND AGE OF THE HAS OF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.wav</td>\n",
       "      <td>e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...</td>\n",
       "      <td>LACED THE CREATION YER NAME AND BADGED OF EACH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.wav</td>\n",
       "      <td>e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...</td>\n",
       "      <td>WHAT IS THE AVERAGE NUMBER OF EMPLOYES OF DEPA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.wav</td>\n",
       "      <td>e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...</td>\n",
       "      <td>WHAT AREE NAMES OF THE HAIRS WHO ARE BORNE OUT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name                                               Path  \\\n",
       "0  0000.wav  e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...   \n",
       "1  0001.wav  e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...   \n",
       "2  0002.wav  e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...   \n",
       "3  0003.wav  e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...   \n",
       "4  0004.wav  e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...   \n",
       "\n",
       "                                                Text  \n",
       "0  HOW MANY HEARS OF THE DEPARTMENT ARE OLDER THA...  \n",
       "1  LACE THE NAME BOARESTATE AND AGE OF THE HAS OF...  \n",
       "2  LACED THE CREATION YER NAME AND BADGED OF EACH...  \n",
       "3  WHAT IS THE AVERAGE NUMBER OF EMPLOYES OF DEPA...  \n",
       "4  WHAT AREE NAMES OF THE HAIRS WHO ARE BORNE OUT...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"transcription.csv\"\n",
    "save = subtitles.drop([\"Path\"], axis = 1)\n",
    "save.loc[save[\"Text\"]==\"\", [\"Text\"]] = \" \"\n",
    "save.to_csv(os.path.join(TRANSCIPTION_PATH, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e59ba9495cf5a0f7daa13e34e418c9fb6692db49850371a2f353821d5213ce6c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ind')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

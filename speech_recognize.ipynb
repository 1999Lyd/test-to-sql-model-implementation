{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(t):\n",
    "    start_time, end_time = map(int, t.split(\"_\"))\n",
    "    dur = end_time - start_time\n",
    "    return start_time, dur\n",
    "    \n",
    "def format_audio(audio_path, audio_file, output_path, format = 'flac'):\n",
    "    try:\n",
    "        audio_name = audio_file.split(\".\")[0]\n",
    "        audio = os.path.join(audio_path, audio_file)\n",
    "        export_path = os.path.join(output_path, audio_name) + f\".{format}\"\n",
    "        cmd = f'ffmpeg -i \\\"{audio}\\\"  -vn -ac 1 -ar {16000} -y \\\"{export_path}\\\"'\n",
    "        subprocess.call(cmd)\n",
    "    except Exception as ex:\n",
    "        print(\"Error: \", ex)\n",
    "    return f\"{export_path}\"\n",
    "\n",
    "def speech2text(path):\n",
    "    # load audio\n",
    "    audio_input, sample_rate = sf.read(path)\n",
    "    # pad input values and return pt tensor\n",
    "    input_values = processor(audio_input, sampling_rate=sample_rate, return_tensors=\"pt\").input_values.to(DEVICE)\n",
    "    # retrieve logits & take argmax\n",
    "    pred = model(input_values)\n",
    "    logits = pred.logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)[0]\n",
    "\n",
    "    # transcribe\n",
    "    transcription = processor.decode(predicted_ids)\n",
    "\n",
    "    return transcription\n",
    "\n",
    "def split_audio(audiopath, audio_name, output_path):\n",
    "    audiotype = audio_name.split(\".\")[-1]\n",
    "    # Read in audio\n",
    "    print('Loading audio..')\n",
    "    sound = AudioSegment.from_file(os.path.join(audiopath, audio_name), format=audiotype)\n",
    "    print(\"Loading done\")\n",
    "    # split\n",
    "    print('Start split')\n",
    "    chunks = split_on_silence(sound,min_silence_len=2000,silence_thresh=-70)#min_silence_len: split if silence is 0.3s。silence_thresh：less than -70dBFS is silence。\n",
    "    # Create saving folder\n",
    "    if not os.path.exists(output_path):os.mkdir(output_path)\n",
    "    print(\"Split done\")\n",
    "    # save splits\n",
    "    print('Saving...')\n",
    "    for i in range(len(chunks)):\n",
    "        new = chunks[i]\n",
    "        save_name = os.path.join(output_path, '%04d.%s'%(i,audiotype))\n",
    "        new.export(save_name, format = 'mp3')\n",
    "        print('%04d'%i,len(new))\n",
    "    print('Save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "BASE_PATH = os.path.abspath(\".\")\n",
    "AUDIO_FOLDER = os.path.join(BASE_PATH, \"Audio\", \"Original\")\n",
    "SPLIT_AUDIO_FOLDER = os.path.join(BASE_PATH, \"Audio\", \"Splitted\")\n",
    "CLEAN_SPEECH_PATH = os.path.join(BASE_PATH, \"Audio\", \"Cleaned\")\n",
    "TRANSCIPTION_PATH = os.path.join(BASE_PATH, \"Transcription\")\n",
    "AUDIO = \"audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_audio(AUDIO_FOLDER, AUDIO, SPLIT_AUDIO_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_NAMES = []\n",
    "for root, dir, files in os.walk(SPLIT_AUDIO_FOLDER):\n",
    "    AUDIO_NAMES += files\n",
    "CLEAN_SPEECH = [format_audio(SPLIT_AUDIO_FOLDER, audio_name, CLEAN_SPEECH_PATH, \"flac\") for audio_name in AUDIO_NAMES]\n",
    "AUDIO_PATH = [os.path.join(CLEAN_SPEECH_PATH, audio_name) for audio_name in CLEAN_SPEECH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles = pd.DataFrame(columns=[\"Name\", \"Path\", \"Text\"])\n",
    "subtitles['Name'] = AUDIO_NAMES\n",
    "subtitles[\"Path\"] = AUDIO_PATH\n",
    "subtitles[\"Text\"] = subtitles[\"Path\"].apply(lambda x: speech2text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Path</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.m4a</td>\n",
       "      <td>e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...</td>\n",
       "      <td>WHAT IS TAMERONS MOSS NATIONALITY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name                                               Path  \\\n",
       "0  0000.m4a  e:\\Graduate\\2021-2022 Term 2\\STA561\\Project\\te...   \n",
       "\n",
       "                                Text  \n",
       "0  WHAT IS TAMERONS MOSS NATIONALITY  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"transcription.csv\"\n",
    "save = subtitles.drop([\"Path\"], axis = 1)\n",
    "save.loc[save[\"Text\"]==\"\", [\"Text\"]] = \" \"\n",
    "save.to_csv(os.path.join(TRANSCIPTION_PATH, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e59ba9495cf5a0f7daa13e34e418c9fb6692db49850371a2f353821d5213ce6c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ind')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
